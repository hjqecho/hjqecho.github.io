<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>0_1Extra.泛化能力证明 | hjqecho</title><meta name="keywords" content="机器学习"><meta name="author" content="hjqecho"><meta name="copyright" content="hjqecho"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="泛化能力证明">
<meta property="og:type" content="article">
<meta property="og:title" content="0_1Extra.泛化能力证明">
<meta property="og:url" content="http://example.com/2022/04/29/0_1Extra.%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E8%AF%81%E6%98%8E/index.html">
<meta property="og:site_name" content="hjqecho">
<meta property="og:description" content="泛化能力证明">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://npm.elemecdn.com/hjqecho_img/custom/1.jpg">
<meta property="article:published_time" content="2022-04-28T16:00:38.000Z">
<meta property="article:modified_time" content="2022-05-12T08:55:17.732Z">
<meta property="article:author" content="hjqecho">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://npm.elemecdn.com/hjqecho_img/custom/1.jpg"><link rel="shortcut icon" href="https://npm.elemecdn.com/hjqecho_img/favicon/favicon.jpg"><link rel="canonical" href="http://example.com/2022/04/29/0_1Extra.%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E8%AF%81%E6%98%8E/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?2f85bba97eb708ee18730491e6beaa52";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '0_1Extra.泛化能力证明',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-12 16:55:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom/custom.css"   media="defer" onload="this.media='all'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://npm.elemecdn.com/hjqecho_img/favicon/favicon.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://npm.elemecdn.com/hjqecho_img/custom/1.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">hjqecho</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">0_1Extra.泛化能力证明</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-04-28T16:00:38.000Z" title="发表于 2022-04-29 00:00:38">2022-04-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-12T08:55:17.732Z" title="更新于 2022-05-12 16:55:17">2022-05-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>36分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="0_1Extra.泛化能力证明"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="泛化能力证明"><a href="#泛化能力证明" class="headerlink" title="泛化能力证明"></a>泛化能力证明</h1><hr>
<blockquote>
<p>参考文章及视频：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43872529/article/details/104362791" title="泛化误差上界的证明">泛化误差上界的证明</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/deepbodhi/article/details/119823871" title="泛化误差上界">泛化误差上界</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yanghh/p/13291411.html" title="马尔可夫(Markov)不等式">马尔可夫(Markov)不等式</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/425562737">尾概率估计方法</a></p>
<p><a target="_blank" rel="noopener" href="https://space.bilibili.com/2374895/channel/seriesdetail?sid=352698&amp;ctype=0">强化学习理论基础 Sound_of_wind的个人空间_bilibili【视频】</a> :+1:</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/102397463">集合论</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148408669">如何通俗的理解矩母函数</a></p>
<p><a target="_blank" rel="noopener" href="https://web.stanford.edu/class/cs229t/2017/Lectures/concentration-slides.pdf">concentration-slides (stanford.edu)</a></p>
</blockquote>
<h2 id="先导"><a href="#先导" class="headerlink" title="先导"></a>先导</h2><h3 id="期望和方差的定义和性质"><a href="#期望和方差的定义和性质" class="headerlink" title="期望和方差的定义和性质"></a>期望和方差的定义和性质</h3><blockquote>
<p>期望的<strong>定义</strong>：</p>
<p>离散型：</p>
<script type="math/tex; mode=display">
\mathbb{E}[X]=\sum_{i}^{n}x_ip_i</script><p>连续型：</p>
<script type="math/tex; mode=display">
\mathbb{E}[X]=\int_{-\infty}^{+\infty}xf(x){\rm d}x</script><p>也称为随机变量X的均值，记做 $\bar{X}$ </p>
<p>期望的<strong>性质</strong>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\mathbb{E}[C]=C,C是常数\\
&\mathbb{E}[aX]=a\mathbb{E}[X],a是常数\\
&\mathbb{E}[aX+bY]=a\mathbb{E}[X]+b\mathbb{E}[Y]\\
&若X,Y相互独立，则\mathbb{E}[XY]=\mathbb{E}[X]\mathbb{E}[Y]
\end{aligned}</script><p>方差的<strong>定义</strong>：</p>
<script type="math/tex; mode=display">
D[X]=Var[X]:=\mathbb{E}[(X-\mathbb{E}[X])^2]</script><p>离散型：</p>
<script type="math/tex; mode=display">
Var[X]=\sum_{i}^{n}(x_i-\mathbb{E}[X])^2p_i</script><p>连续型：</p>
<script type="math/tex; mode=display">
Var[X]=\int_{-\infty}^{+\infty}(x-\mathbb{E}[X])^2f(x){\rm d}x</script><p>方差的<strong>性质</strong>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&Var[C]=0,C是常数\\
&Var[CX]=C^2Var[X]\\
&Var[aX+bY]=a^2Var[X]+b^2Var[Y]+2ab\mathbb{E}[X-EX]\mathbb{E}[Y-EY]\\
&若X,Y相互独立，则Var[aX+bY]=a^2Var[X]+b^2Var[Y]\\
&Var[X+b]=Var[X]\\
&Var[aX+b]=a^2Var[X]\\
&Var[X]=\mathbb{E}[X^2]-\mathbb{E}^2[X]
\end{aligned}</script></blockquote>
<h3 id="样本期望和方差的无偏估计"><a href="#样本期望和方差的无偏估计" class="headerlink" title="样本期望和方差的无偏估计"></a>样本期望和方差的无偏估计</h3><p>假设 $X_1,X_2,X_3,….,X_n$ 是一个独立同分布( $i.i.d$ )随机变量序列，假设其均值 $\mu=\mathbb{E}[X]$ 及其方差 $\sigma^2=Var[X]$ 均存在。若采用如下估计量来估计 $\mu$ ，用 $\hat\mu$ 表示，同时 $\hat\mu$ 也是样本均值 $\bar{X}$ ：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\bar{X}&=\hat{\mu}=\frac{1}{N}\sum_{i=1}^{n}X_i\\
\end{aligned}</script><blockquote>
<p>无偏估计的<strong>定义</strong>：</p>
<script type="math/tex; mode=display">
\mathbb{E}[\theta]=\theta</script></blockquote>
<p>样本均值期望满足无偏估计，<strong>证明</strong>如下：</p>
<p><em>Proof:</em></p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}[\hat{\mu}]&=\mathbb{E}[\frac{1}{N}\sum_{i=1}^{N}X_i]\\
&=\frac{1}{N}\sum_{i=1}^{N}\underset{\mu}{\underbrace{\mathbb{E}[X_i]}}\\
&=\frac{1}{N}\cdot N\cdot\mu=\mu
\end{aligned}</script><p> $\square$ </p>
<blockquote>
<p>在总体方差中，设 $S^2$ 为其方差，表达式为：</p>
<script type="math/tex; mode=display">
S^2=\cfrac{1}{N}\sum_{i=1}^N(X_i-\bar{X})^2</script></blockquote>
<p>对于 $\hat\mu$ 的方差如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
Var(\hat\mu)&=Var[\frac{1}{N}\sum_{i=1}^{N}X_i]\\
&=\frac{1}{N^2}\sum_{i=1}^{N}\underset{\sigma^2}{\underbrace{Var(X_i)}}\\
&=\frac{1}{N^2}\cdot N\cdot \sigma^2\\
&=\frac{\sigma^2}{N}
\end{aligned}</script><p>总体方差是有偏估计，<strong>证明</strong>如下：</p>
<p><em>Proof:</em></p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}[\cfrac{1}{N}\sum_{i=1}^{N}(X_i-\bar{X})^2]&=\cfrac{1}{N}\mathbb{E}[\sum_{i=1}^{N}[(X_i-\mu)-(\bar{X}-\mu)]^2]\\
&=\cfrac{1}{N}\mathbb{E}[\sum_{i=1}^{N}(X_i-\mu)^2-2(\bar{X}-\mu)\sum_{i=1}^{N}(X_i-\mu)+N(\bar{X}-\mu)^2]\\
&\because\sum_{i=1}^{N}(X_i-\mu)=N(\bar{X}-\mu)\\
&=\cfrac{1}{N}\mathbb{E}[\sum_{i=1}^{N}(X_i-\mu)^2-N(\bar{X}-\mu)^2]\\
&\because\mathbb{E}[(X_i-\mu)^2]=Var(X_i)=\sigma^2\\
&\ \quad\mathbb{E}[(\bar{X}-\mu)^2]=Var(\bar{X})=Var(\hat\mu)=\cfrac{\sigma^2}{N}\\
&=\cfrac{1}{N}(N\sigma^2-N\cdot\cfrac{\sigma^2}{N})\\
&=\cfrac{(N-1)}{N}\sigma^2
\end{aligned}</script><p>当对上式( $\cfrac{1}{N}\sum_{i=1}^{N}(X_i-\bar{X})^2$ )乘上 $\cfrac{N}{N-1}$ 后即可让其方差，达成无偏估计无偏方差为：</p>
<script type="math/tex; mode=display">
S^2=\cfrac{1}{N-1}\sum_{i=1}^{N}(X_i-\bar{X})^2</script><p> $\square$ </p>
<h3 id="尾概率"><a href="#尾概率" class="headerlink" title="尾概率"></a>尾概率</h3><p>那么 $\mu$ （期望）和 $\hat\mu$ （样本期望）之间大概差多少？</p>
<p>通常使用 $|\hat\mu-\mu|\ge\epsilon$ ， $\epsilon$ 是设置的一个阈值，当超过这个时则认为差距大，不超过时则认为不大，那么通过计算 $P(|\hat\mu-\mu|\ge\epsilon)$ 如果这个值很小则认为 $\hat\mu$ 是符合要求的， $P(|\hat\mu-\mu|\ge\epsilon)$ 就称为尾概率。</p>
<blockquote>
<p>定义：若X是一个构成均值为 $\mu$ 的随机变量， $\epsilon$ 是一个常数：</p>
<ul>
<li>$P(X\ge\mu+\epsilon)$ 称为右尾概率（upper tail probability）</li>
<li>$P(X\le\mu-\epsilon)$ 称为左尾概率（lower tail probability）</li>
<li>$P(|X-\mu|\ge\epsilon)$ 称为双尾概率（two-sided tail probability）</li>
</ul>
</blockquote>
<p><img src="https://npm.elemecdn.com/hjqecho_img/0_1Extra.泛化能力证明/image-20220125151830804.png" alt="image-20220125151830804" style="zoom:33%;" /></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数是用来度量模型一次预测的好坏，通常用 $L(Y,f(x))$ 来表示，常见的损失函数有：</p>
<ul>
<li>0-1损失函数</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
L(Y,f(X))=\begin{cases}1,\quad Y\neq f(X) \\ 0,\quad Y=f(X) \end{cases}
\end{aligned}</script><ul>
<li>平方损失函数</li>
</ul>
<script type="math/tex; mode=display">
L(Y,f(X))=(Y-f(X))^2</script><ul>
<li>绝对值损失函数</li>
</ul>
<script type="math/tex; mode=display">
L(Y,f(X))=|Y-f(X)|</script><ul>
<li>对数似然损失函数</li>
</ul>
<script type="math/tex; mode=display">
L(Y,P(Y|X))=-lnP(Y|X)</script><hr>
<h3 id="风险函数"><a href="#风险函数" class="headerlink" title="风险函数"></a>风险函数</h3><p>风险函数则是损失函数的平均。</p>
<p>若是在训练样本集上的平均，则称为<strong>经验风险</strong>或<strong>经验损失</strong>（Empirical Risk/Loss），记作 $R_{emp}(f)$ 。给定训练集 $T=\{(x_1,y_1),(x_2,y_2),…,(x_n,y_n)\}$ ，则：</p>
<script type="math/tex; mode=display">
R_{emp}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))</script><p>若是在样本空间上的期望，相当于在全集中进行度量。则为<strong>期望风险</strong>或<strong>期望损失</strong>（Expected Risk/Loss），记作 $R_{exp}(f)$ 。模型的输入、输出 $(X,Y)$ 是随机变量，遵循联合分布 $P(X,Y)$ ，则：</p>
<script type="math/tex; mode=display">
\begin{aligned}
R_{exp}(f)\ &=\ \mathbb{E}_p[L(Y,f(X))] \\
&= \int_{X\times Y}L(y,f(x))P(x,y)dxdy
\end{aligned}</script><p>模型训练的终极目的是为了降低期望风险。但由于联合分布 $P(X,Y)$ 是未知的，所以期望风险只存在理论意义。</p>
<p>根据大数定律，当样本容量 $N$ 趋于无穷时，经验风险趋于期望风险。因此，在实际训练时，我们可以用经验风险去近似期望风险。针对样本容量大小，存在两种训练策略：经验风险最小(经验损失最小)策略和结构风险最小(<strong>结构风险=经验风险+正则化项</strong>)策略。正则化参考<a href=".\2.LinearRegression.md">2.LinearRegression.md</a>中的L1和L2正则化。</p>
<script type="math/tex; mode=display">
\begin{aligned}
R_{srm}(f)&=R_{emp}+\lambda J(f)\\
&=\frac{1}{N}\sum_{n=1}^{N}L(y,f(x,f))+\lambda J(f)
\end{aligned}</script><p>当样本容量足够大时，经验风险最小策略就能保证较好的训练效果，即：</p>
<script type="math/tex; mode=display">
\underset{f\in F}{min}R_{emp}(f)</script><p>如果训练样本有限，经验风险最小策略就会产生“过拟合”，可在经验风险的基础上增加表示模型复杂度的正则化项（惩罚项），即结构风险最小策略（Structural Risk Minimization, SRM）:</p>
<script type="math/tex; mode=display">
\underset{f\in F}{min}R_{srm}(f)=\underset{f\in F}{min}[R_{emp}(f)+\lambda J(f)]</script><p>其中， $J(f)$ 表示模型复杂度，是定义在假设空间 $F$ 上的泛函， $f$ 越复杂， $J(f)$ 越大，比如在多项式函数空间，多项式系数的平方和可作为度量函数复杂度的指标。 $\lambda \ge 0$ 是正则化系数，用于权衡经验风险和模型复杂度，即用来控制正则化项（惩罚项）惩罚力度。<br>正则化方法符合奥卡姆剃刀原理：在所有可能的模型中，能够很好解释已有数据，且最简单的模型才是最好的模型。这样的模型泛化能力强。</p>
<hr>
<h2 id="霍夫丁不等式的证明"><a href="#霍夫丁不等式的证明" class="headerlink" title="霍夫丁不等式的证明"></a>霍夫丁不等式的证明</h2><p>证明霍夫丁不等式，需要先证明马尔可夫不等式、切比雪夫不等式、切诺夫界和霍夫丁引理，才能够对霍夫丁不等式进行证明，这些不等式也叫集中不等式。</p>
<script type="math/tex; mode=display">
\begin{aligned}
&马尔可夫不等式\\
\Rightarrow&切比雪夫不等式\\
\Rightarrow&切诺夫界\\
\Rightarrow&霍夫丁引理\\
\Rightarrow&霍夫丁不等式
\end{aligned}</script><h3 id="一、Markov’s-Inequality（马尔可夫不等式）"><a href="#一、Markov’s-Inequality（马尔可夫不等式）" class="headerlink" title="一、Markov’s Inequality（马尔可夫不等式）"></a>一、Markov’s Inequality（马尔可夫不等式）</h3><p>马尔可夫不等式把概率关联到数学期望，给出了随机变量的分布函数的一个宽泛但仍有用的上界。 </p>
<blockquote>
<p><strong>马尔可夫不等式</strong>：</p>
<p>令 $X$ 为非负随机变量，且假设 $E(X)$ 存在，则对任意的 $\epsilon&gt;0$ 有</p>
<script type="math/tex; mode=display">
P\{X\ge \epsilon\}\le\frac{\mathbb{E}(X)}{\epsilon}</script></blockquote>
<p>马尔可夫不等式是用来估计尾部事件的概率上界，一个直观的例子是：如果 $X$ 是工资，那么 $\mathbb{E}(X)$ 就是平均工资，假设 $\epsilon=n*\mathbb{E}(X)$ ，即平均工资的 $n$ 倍。那么根据马尔可夫不等式，不超过 $\frac{1}{n}$ 的人会有超过平均工资的 $n$ 倍的工资。</p>
<p><strong>证明</strong>如下:</p>
<p><em>Proof~1~:</em></p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}(X)&=\int_0^{+\infty}xf(x)dx\\
&=\int_0^\epsilon xf(x)dx+\int_\epsilon^{+\infty}xf(x)dx\\
&\ge\int_\epsilon^{+\infty}xf(x)dx\\
&\ge \epsilon\int_\epsilon^{+\infty}f(x)dx\\
&=\epsilon P\{X\ge \epsilon\}\\
\Rightarrow &P\{X\ge \epsilon\}\le \frac{\mathbb{E}(X)}{\epsilon}&
\end{aligned}</script><p><em>Proof~2~:</em></p>
<script type="math/tex; mode=display">
\begin{aligned}
P(X\ge \epsilon)&=\int_{X\ge \epsilon}p(x)dx\qquad(1)\\
&\le\int_{X\ge \epsilon}\frac{x}{\epsilon}p(x)dx\quad(2)\\
&=\frac{1}{\epsilon}\int_{X\ge \epsilon}xp(x)dx\\
&\le\frac{1}{\epsilon}\int_{0}^{+\infty}xp(x)dx\\
&=\frac{\mathbb{E}(X)}{\epsilon}
\end{aligned}</script><p>由 $(1)$ 变到 $(2)$ 可由 $P(X\ge \epsilon)$ 中的 $X\ge \epsilon$ 得出，将 $\epsilon$ 移到右边得到 $\frac{X}{\epsilon}\ge1$ ，带入 $(1)$ 式可得 $(2)$ 式。</p>
<hr>
<p>将该不等式推广到概率测度空间上：</p>
<blockquote>
<p>设 $(\Omega,\mathscr{F},\mathbb{P})$ 为概率空间， $X$ 为非负实值随机变量，对任意 $\epsilon&gt;0$ ，则有 $\mathbb{P}(w\in\Omega:X(w)\ge\epsilon)\le\cfrac{1}{\epsilon}\int_{\Omega}X(w)d\mathbb{P}$ </p>
</blockquote>
<p><em>proof：</em></p>
<p><a href=".\0_1Extra.数学定义.md#probability">概率空间</a> </p>
<p>令阶梯函数</p>
<script type="math/tex; mode=display">
S(w)=\begin{cases}\epsilon&,X(w)\ge\epsilon\\0&,X(w)<\epsilon\end{cases}</script><p>显然有 $0\le S(w)\le X(w)$ ，</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}[X]
&=\int_{\Omega}X(w){\rm d}\mathbb{P}\\
&\ge\int_{\Omega}S(w){\rm d}\mathbb{P}\\
&=\underset{0}{\underbrace{\int_0^\epsilon S(w){\rm d}\mathbb{P}}}
+\underset{\epsilon\int_\epsilon^\infty{\rm d}\mathbb{P}}
{\underbrace{\int_\epsilon^\infty S(w){\rm d}\mathbb{P}}}\\
&=\epsilon\underset{\mathbb{P}(X\ge\epsilon)}
{\underbrace{\mathbb{P}(\{w\in\Omega:X(w)\ge\epsilon\}}})\\
&\Rightarrow\mathbb{E}[X]\ge\epsilon\mathbb{P}(X\ge\epsilon)\\
&\because\epsilon\gt0\\
&\therefore\cfrac{\mathbb{E}[X]}{\epsilon}\ge\mathbb{P}(X\ge\epsilon)
\end{aligned}</script><p> $\square$ </p>
<h3 id="二、Chebyshev’s-Inequality（切比雪夫不等式）"><a href="#二、Chebyshev’s-Inequality（切比雪夫不等式）" class="headerlink" title="二、Chebyshev’s Inequality（切比雪夫不等式）"></a>二、Chebyshev’s Inequality（切比雪夫不等式）</h3><p>切比雪夫不等式是马尔可夫不等式的特殊情况，其不限定随机变量的范围，应用更广泛。</p>
<blockquote>
<p><strong>切比雪夫不等式：</strong></p>
<p>若任意随机变量 $(r.v)X$ 的期望和方差都存在，分别为 $E(X)$ 和 $Var(X)$ ，则有：</p>
<script type="math/tex; mode=display">
P\{|X-\mathbb{E}(X)|\ge \epsilon\}\le\frac{Var(X)}{\epsilon^2},\epsilon>0</script></blockquote>
<p><em>Proof~1~：</em></p>
<p>任取 $\epsilon&gt;0$ </p>
<script type="math/tex; mode=display">
\begin{aligned}
P\{|X-\mathbb{E}(X)|\ge\epsilon\}&=\color{red}{P\{|X-\mathbb{E}(X)|^2\ge\epsilon^2\}}\\
&\color{red}{\le\frac{\mathbb{E}\{|X-\mathbb{E}(X)|^2\}}{\epsilon^2}}\\
&=\frac{Var(X)}{\epsilon^2}
\end{aligned}</script><p> $\square$ </p>
<p>红色部分使用的是马尔科夫不等式</p>
<p><em>Proof~2~：</em></p>
<p>使用和Markov不等式类似的证明方法，通过放缩的方式也可以获得这一结果</p>
<script type="math/tex; mode=display">
\begin{aligned}
记D:|X-\mathbb{E}(X)|\ge\epsilon\\
P\{|X-\mathbb{E}(X)|\ge\epsilon\}&=\color{red}{\int_{D}f(x)dx}\\
&\color{red}{\le\int_D(\frac{|X-E(X)|}{\epsilon})^2f(x)dx}\\
&=\frac{1}{\epsilon^2}\int_D(X-\mathbb{E}(X))^2f(x)dx\\
&\le\frac{1}{\epsilon^2}\int_{-\infty}^{+\infty}(X-\mathbb{E}(X))^2f(x)dx\\
&=\frac{1}{\epsilon^2}Var(X)
\end{aligned}</script><p> $\square$ </p>
<p>红色部分是 $|X-\mathbb{E}(X)|\ge\epsilon$ 得到的 $\frac{|X-\mathbb{E}(X)|}{\epsilon}\ge1$ 代入。</p>
<h3 id="三、Chernoff’s-bound（切诺夫界）"><a href="#三、Chernoff’s-bound（切诺夫界）" class="headerlink" title="三、Chernoff’s bound（切诺夫界）"></a>三、Chernoff’s bound（切诺夫界）</h3><p>在实际应用中，由于Markov不等式和Chebyshev不等式仅用到了随机变量的一阶和二阶矩（期望和方差）特征，通常得到的界较为宽松。我们希望能够找到一个更为紧确的界。</p>
<p>上面的切比雪夫不等式使用的是 $(X-\mathbb{E}[X])^2$ 那么也可以使用 $(X-\mathbb{E}[X])^k$ ，k为任意常数，k可能是奇数使用使用 $|X-\mathbb{E}[X]|^k$ ,再使用马尔科夫不等式得到 $\mathbb{P}(|X-\mathbb{E}[X]|\ge\epsilon)\le\cfrac{\mathbb{E}[|X-\mathbb{E}|^k]}{\epsilon^k}$ ，在这些上界中（不同的k值）可以得到一个更小的，更紧的上界，但是对于$k$的计算也较为复杂。我们需要一个界它足够的紧，又比较方便计算，那么切诺夫界正好就满足了这两个要求，它的右侧是矩母函数，首先先介绍矩母函数。</p>
<blockquote>
<p><strong>矩母函数</strong>：</p>
<p>假设X为一个随机变量 $(r.v.)$ ，若存在 $h&gt;0$ 使得对于任意 $t\in[0,h],\mathbb{E}[e^{t X}]$ 均存在，则称存在矩母函数（MGF），记作 $M_x(t)$ ，定义式为：</p>
<script type="math/tex; mode=display">
M_X(t):=\mathbb{E}[e^{tX}]=
\begin{cases}
\sum_xe^{tx}\cdot \underset{PMF}{\underbrace{P(x)}}&x:discrete(离散)\\
\int_xe^{tx}\cdot \underset{PDF}{\underbrace{f(x)}}dx&x:continuous(连续)
\end{cases}\\
\begin{aligned}
&PDF:概率密度函数（probability density function），连续型\\
&PMF:概率质量函数（probability mass function), 离散型
\end{aligned}</script></blockquote>
<p>矩母函数有一个较好的性质</p>
<blockquote>
<p><strong>性质</strong>：取 $n$ 次 $M_x(t)$ 的导数并令 $t=0$ ，就可以得到 $\mathbb{E}(X^n)$ 也叫 $n$ 阶矩。即</p>
<script type="math/tex; mode=display">
M_X^{(n)}(0)=\mathbb{E}[X^n]=\cfrac{ {\rm d}^n}{ {\rm d}t^n}M_X(0)</script><p>矩母函数(MGF)其实就可以看做矩生成函数，可以通过求导获取到想对应的矩。</p>
</blockquote>
<p><em>Proof:</em></p>
<p>使用泰勒级数可以得到</p>
<script type="math/tex; mode=display">
\begin{aligned}
&e^x\ =1+\ x\ +\ \ \cfrac{x^2}{2!}\ \ +\ \ \cfrac{x^3}{3!}\ \ +\cdots+\ \ \cfrac{x^n}{n!}\\
\Rightarrow
&e^{tx}=1+tx+\cfrac{(tx)^2}{2!}+\cfrac{(tx)^3}{3!}+\cdots+\cfrac{(tx)^n}{n!}
\end{aligned}</script><p>然后取得期望</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}[e^{tX}]&=
\mathbb{E}[1+tX+\cfrac{(tX)^2}{2!}+\cfrac{(tX)^3}{3!}+\cdots+\cfrac{(tX)^n}{n!}]\\
&=\mathbb{E}[1]+t\mathbb{E}[X]+\cfrac{t^2}{2!}\mathbb{E}[X^2]
+\cfrac{t^3}{3!}\mathbb{E}[X^3]+\cdots+\cfrac{t^n}{n!}\mathbb{E}[X^n]
\end{aligned}</script><p>假如对 $t$ 求 $1$ 阶导可得</p>
<script type="math/tex; mode=display">
\begin{aligned}
\cfrac{ {\rm d}}{ {\rm d}t}\mathbb{E}[e^{tX}]&=
\cfrac{ {\rm d}}{ {\rm d}t}(\mathbb{E}[1]+t\mathbb{E}[X]+\cfrac{t^2}{2!}\mathbb{E}[X^2]
+\cfrac{t^3}{3!}\mathbb{E}[X^3]+\cdots+\cfrac{t^n}{n!}\mathbb{E}[X^n])\\
&求完导后代入t=0\\
&=0+\mathbb{E}[X]+0+0+\cdots+0\\
&=\mathbb{E}[X]
\end{aligned}</script><p>同理2,3阶导也可求得 $\square$ </p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148408669#:~:text=%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC,%E9%9C%80%E8%A6%81MGF">为什么我们需要矩母函数</a></p>
<blockquote>
<p><strong>重尾和轻尾</strong>：</p>
<p>若随机变量 $X$ 满足 $\mathbb{E}[e^{tX}]=\infty,\forall t\gt 0$ ，则称为重尾，否则就称为轻尾。</p>
</blockquote>
<p>重尾的就是指矩母函数不存在，轻尾的是指矩母函数存在。</p>
<p>通过指数函数来了解这个概念，指数分布定义如下：</p>
<script type="math/tex; mode=display">
f(x)=
\begin{cases}
\lambda\cdot e^{-\lambda x}&,x\ge 0\\
0&,x\lt 0
\end{cases}</script><p>求得矩母函数为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
M_X(t)=\mathbb{E}[e^{tX}]&=\int_0^\infty e^{tx}\cdot\lambda e^{-\lambda x}{\rm dx}\\
&=\lambda\int_0^\infty e^{(t-\lambda)x}{\rm dx}\\
&=\lambda\Big|\cfrac{1}{t-\lambda}e^{(t-\lambda)x}\Big|_0^\infty\\
&=\begin{cases}
\infty&,t-\lambda\gt 0\\
\cfrac{\lambda}{\lambda-t}&,t-\lambda\lt 0
\end{cases}
\end{aligned}</script><p>可以看只有当 $t-\lambda\lt0$ 时才收敛，才能求出期望，一但求出 $\cfrac{\lambda}{\lambda-t}$ ，计算矩就变成了求导的问题，比积分更容易计算期望值。</p>
<hr>
<p>设 $t\in(0,\infty)$ ，</p>
<p>有函数 $f(x)=\exp{(tx)}$ ，明显 $f(x)$ 单增，所以 $x_1\ge x_2\Rightarrow f(x_1)\ge f(x_2)$ ；</p>
<p>逆函数 $f^{-1}(x)=\frac{1}{t}\ln{(x)}$ ， $f^{-1}(x)$ 单增，所以 $f(x_1)\ge f(x_2)\Rightarrow X_1\ge x_2$ 。</p>
<p>综上可得： $x_1\ge x_2 \Leftrightarrow f(x_1)\ge f(x_2)$ 。</p>
<p>综上可以推出以下不等式</p>
<script type="math/tex; mode=display">
\mathbb{P}[(x-\mu)\ge\epsilon]
=\mathbb{P}[e^{t(x-\mu)}\ge e^{t\epsilon}]
\le\cfrac{\mathbb{E}[e^{t(X-\mu)}]}{e^{t\epsilon}},\forall\lambda\in[0,h]</script><p>不等式部分使用的是马尔科夫不等式，因为 $\lambda$ 的不同，取得的上界也是不同的，所以我们就要获取一个更紧更小的下确界，这个最紧的界就是要介绍的切诺夫界。</p>
<blockquote>
<p><strong>切诺夫界</strong>：</p>
<p>对任意的 $r.v.\ X$ ，假设其均值存在且为 $\mu$ ，并且其矩母函数 $M_X(t),t\in[0,h]$ ，存在，则 $X$ 的切诺夫界定义为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{P}[(X-\mu)\ge\epsilon]
&\le\inf_{\lambda\in[0,h]}\cfrac{\mathbb{E}[e^{t(X-\mu)}]}{e^{t\epsilon}}\\
&=\inf_{\lambda\in[0,h]}\cfrac{\mathbb{E}[e^{(tX-t\mu)}]}{e^{t\epsilon}}\\
&\overset{常数e^{t\mu}}{=}\inf_{\lambda\in[0,h]}\cfrac{\mathbb{E}[e^{tX}]}
{e^{t\epsilon+t\mu}}\\
&=\inf_{\lambda\in[0,h]}\cfrac{M_X(t)}
{e^{t\epsilon+t\mu}}
\end{aligned}</script><p>同时也可以得到一般情况下，令 $\mathbb{E}[X]=\mu=0$ 得：</p>
<script type="math/tex; mode=display">
\mathbb{P}(X\ge\epsilon)\le\inf_{\lambda\gt0}\cfrac{\mathbb{E}[e^{tX}]}{e^{t\epsilon}}\\</script></blockquote>
<p>现在通过正态分布 $X\sim N(\mu,\sigma^2)$ 了解切诺夫界：</p>
<script type="math/tex; mode=display">
\begin{aligned}
M_X(t)&=\mathbb{E}[e^{tX}]\\
&=\int_{-\infty}^\infty e^{tx}\cfrac{1}{\sqrt{2\pi}\sigma}
e^{-\frac{(x-\mu)^2}{2\sigma^2}}{\rm d}x\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{(tx-\cfrac{(x-\mu)^2}{2\sigma^2})}{\rm d}x\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{(\cfrac{2tx\sigma^2-x^2+2x\mu-\mu^2}{2\sigma^2})}{\rm d}x\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{(-\cfrac{x^2-2x(\mu+t\sigma^2)+\mu^2}{2\sigma^2})}{\rm d}x\\
&对\exp中分子前两项凑平方，消去与x的无关项\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{\Bigg(-\cfrac{x^2-2x(\mu+t\sigma^2)+(\mu+t\sigma^2)^2+\mu^2-(\mu+t\sigma^2)^2}{2\sigma^2}\Bigg)}{\rm d}x\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{\Bigg(-\cfrac{[x-(\mu+t\sigma^2)]^2+\mu^2-\mu^2-2\mu t\sigma^2-(t\sigma^2)^2}{2\sigma^2}\Bigg)}{\rm d}x\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{\Bigg(-\cfrac{[x-(\mu+t\sigma^2)]^2}{2\sigma^2}+\mu t+\cfrac{t^2\sigma^2}{2}\Bigg)}{\rm d}x\\
&=\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{\Bigg(-\cfrac{[x-(\mu+t\sigma^2)]^2}{2\sigma^2}\Bigg)\exp{\Bigg(\mu t+\cfrac{t^2\sigma^2}{2}}\Bigg)}{\rm d}x\\
&\exp后半部分与x无关，可以看做常数\\
&=\exp{\Bigg(\mu t+\cfrac{t^2\sigma^2}{2}}\Bigg)\cdot\int_{-\infty}^\infty\cfrac{1}{\sqrt{2\pi}\sigma}\
\exp{\Bigg(-\cfrac{[x-(\mu+t\sigma^2)]^2}{2\sigma^2}\Bigg)}{\rm d}x\\
\end{aligned}</script><p>后面的积分结果必为1，因为其满足 $X\sim N(\mu+t\sigma^2,\sigma^2)$ 的高斯分布，所以取得最终结果为：</p>
<script type="math/tex; mode=display">
M_X(t)=\exp{(\mu t+\cfrac{t^2\sigma^2}{2})}</script><p>显然 $M_X(t)$ 对任意 $t\gt 0$ 均有定义</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\inf_{t\gt 0}\cfrac{\mathbb{E}[e^{t(X-\mu)}]}{e^{t\epsilon}}\\
=&\inf_{t\gt 0}\cfrac{M_X(t)}{e^{t\epsilon+t\mu}}\\
=&\inf_{t\gt 0}\cfrac{e^{(\mu t+\frac{t^2\sigma^2}{2})}}{e^{t\epsilon+t\mu}}\\
=&\inf_{t\gt 0}e^{(\frac{t^2\sigma^2}{2}-t\epsilon)}
\end{aligned}</script><p>接下来求得最小值即可，因为指数函数是单调函数得：</p>
<script type="math/tex; mode=display">
{\rm argmin}_{t\gt0}\{e^{(\frac{t^2\sigma^2}{2}-t\epsilon)}\}={\rm argmin}_{t\gt0}\{\frac{t^2\sigma^2}{2}-t\epsilon\}</script><p>将上式对 $t$ 求导得：</p>
<script type="math/tex; mode=display">
\cfrac{ {\rm d}\Big(\cfrac{t^2\sigma^2}{2}-t\epsilon\Big)}{ {\rm d}t}=\sigma^2t-\epsilon</script><p>然后令等式对于0求得驻点</p>
<script type="math/tex; mode=display">
\sigma^2t-\epsilon\Rightarrow t=\cfrac{\epsilon}{\sigma^2}</script><p>代入 $t$ ，求得高斯分布切诺夫界为：</p>
<script type="math/tex; mode=display">
e^{(\frac{t^2\sigma^2}{2}-t\epsilon)}
=e^{(\frac{\epsilon^2}{2\sigma^2}-\frac{\epsilon^2}{\sigma^2})}
=e^{-\frac{\epsilon^2}{2\sigma^2}}\\
\Rightarrow\mathbb{P}[(X-\mu)\ge\epsilon]\le e^{-\frac{\epsilon^2}{2\sigma^2}}</script><hr>
<h3 id="Hoeffding’s-Lemma（霍夫丁引理）"><a href="#Hoeffding’s-Lemma（霍夫丁引理）" class="headerlink" title="Hoeffding’s Lemma（霍夫丁引理）"></a>Hoeffding’s Lemma（霍夫丁引理）</h3><blockquote>
<p><strong>次高斯性</strong>：</p>
<p>设 $X$ 是一个均值为 $\mu=\mathbb{E}[X]$ 的 $r.v.$ ，若存在 $\sigma\lt 0$ 使得:</p>
<script type="math/tex; mode=display">
\mathbb{E}[e^{\lambda(X-\mu)}]\le e^{\frac{\sigma^2\lambda^2}{2}}\quad\forall\lambda\in\mathbb{R}</script><p>则称它为 $\sigma$ 次高斯，其中 $\sigma$ 称作次高斯参数。</p>
<p><strong>定理</strong>：</p>
<p>若 $X$ 为 $\sigma$ 次高斯随机变量，则 $X$ 满足：</p>
<script type="math/tex; mode=display">
\mathbb{P}[(X-\mu)\ge\epsilon]\le e^{-\frac{\epsilon^2}{2\sigma^2}}</script></blockquote>
<p><em>Proof</em>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{P}[(X-\mu)\ge\epsilon]&=\mathbb{P}[e^{\lambda(X-\mu)}\ge e^{\lambda\epsilon}]\\
&\le\mathbb{E}[e^{\lambda(X-\mu)}]e^{-\lambda\epsilon}(马尔可夫不等式)\\
&\le e^{\frac{\lambda^2\sigma^2}{2}}e^{-\lambda\epsilon}(次高性定义)\\
&=e^{(\frac{\lambda^2\sigma^2}{2}-\lambda\epsilon)}
\end{aligned}</script><p>将 $\lambda=\frac{\epsilon}{\sigma^2}$ (在切诺夫的正态分布中求过)待入上式，得：</p>
<script type="math/tex; mode=display">
\mathbb{P}[(X-\mu)\ge\epsilon]\le e^{-\frac{\epsilon^2}{2\sigma^2}}</script><p> $\square$ </p>
<blockquote>
<p><strong>函数的凹凸性</strong>：</p>
</blockquote>
<p><em>Proof</em>：</p>
<p>设函数 $f(x)$ 在区间 $I$ 上有定义，在 $I$ 内任取两点 $x_1,x_2$ ，对任意的 $\lambda\in[0,1]$ ，有 $\lambda x_1+(1-\lambda)x_2\in[x_1,x_2]$ 。</p>
<p><img src="https://npm.elemecdn.com/hjqecho_img/0_1Extra.泛化能力证明/2022-03-07-18-04-16-image.png" style="zoom: 25%;" /></p>
<p> $A_1$ 点坐标 $(x_1,f(x_1))$ ， $A_2$ 点坐标 $(x_2,f(x_2))$ ，$A$ 点坐标 $(x,f(x))$ ，于是可求得：</p>
<script type="math/tex; mode=display">
y_B=\cfrac{x_2-x}{x_2-x_1}f(x_1)+\cfrac{x-x_1}{x_2-x_1}f(x_2)</script><p>可以得到 $y_B$ 是关于 $X$ 的一条直线，且 $A_1,A_2$ 均在直线上，令 $\lambda=\cfrac{x_2-x}{x_2-x_1}$ ，则：</p>
<script type="math/tex; mode=display">
y_B=\lambda f(x_1)+(1-\lambda)f(x_2)</script><p>可以得到 $y_B$ 的值在 $y_1$ 和 $y_2$ 之间。易推出：</p>
<script type="math/tex; mode=display">
x=\lambda x_1+(1-\lambda)x_2</script><p>通过函数图像可得</p>
<script type="math/tex; mode=display">
y_A\le y_B</script><p>所以</p>
<script type="math/tex; mode=display">
f(x)\le\cfrac{x_2-x}{x_2-x_1}f(x_1)+\cfrac{x-x_1}{x_2-x_1}f(x_2)</script><p>即</p>
<script type="math/tex; mode=display">
f[\lambda x_{1} + (1-\lambda )x_{2}] \leq \lambda f(x_{1}) + (1-\lambda )f(x_{2}),\lambda \in (0,1)</script><p>满足这个性质的函数称为凹函数，同理可证凸函数。</p>
<blockquote>
<p><strong>霍夫丁引理</strong>：</p>
<p>设随机变量 $X\in[a,b]$ ，对任意的 $\lambda\in R$ 有：</p>
<script type="math/tex; mode=display">
\mathbb{E}\big[e^{\lambda(X-\mathbb{E}[X])}\big]
\le\exp{\{\cfrac{\lambda^2(b-a)^2}{8}\}}</script></blockquote>
<p><em>Proof~1~</em>：</p>
<p>为了使推导更加的简洁，令 $E(X)=0$ ，如果取其他值也不用影响结果，所以:</p>
<script type="math/tex; mode=display">
\mathbb{E}\big[e^{\lambda(X-\mathbb{E}[X])}\big]=\mathbb{E}\big[e^{\lambda X}\big]</script><p>其中 $e^{\lambda x}$ 在区间 $[a,b]$ 上是凹函数，由凹函数的性质可得</p>
<script type="math/tex; mode=display">
e^{\lambda X} \leq \frac{b-X}{b-a}e^{\lambda a} + \frac{X-a}{b-a}e^{\lambda b}</script><p>对不等式两边求数学期望有</p>
<script type="math/tex; mode=display">
\mathbb{E}[e^{\lambda X}]\leq\frac{b-\mathbb{E}[X]}{b-a}e^{\lambda a}
+\frac{\mathbb{E}[X]-a}{b-a}e^{\lambda b}</script><p>因为 $\mathbb{E}[X]=0$ ，所以</p>
<script type="math/tex; mode=display">
\mathbb{E}[e^{\lambda X}]\leq\frac{b}{b-a}e^{\lambda a}
-\frac{a}{b-a}e^{\lambda b}</script><p>对右侧表达式进行变换</p>
<script type="math/tex; mode=display">
\frac{b}{b-a}e^{\lambda a}-\frac{a}{b-a}e^{\lambda b}
=e^{\lambda a}(\frac{b}{b-a}-\frac{a}{b-a}e^{\lambda(b-a)})
=exp\left\{\lambda a+ln(\frac{b}{b-a}-\frac{a}{b-a}e^{\lambda (b-a)})\right\}</script><p>将最复杂的部分进行换元，令 $h=\lambda(b-a),p=\frac{-a}{b-a}$ 则有：</p>
<script type="math/tex; mode=display">
exp\{\lambda a+ln(\frac{b}{b-a}-\frac{a}{b-a}e^{\lambda(b-a)})\}
=exp\{-hp+ln(1-p+pe^{h})\}</script><p>对于函数</p>
<script type="math/tex; mode=display">
L(h)=-hp+\ln (1-p+pe^h)</script><p>利用泰勒公式将其在 $x=0$ 处展开，得：</p>
<script type="math/tex; mode=display">
L(h)=L(0)+L'(0)h+\frac{L''(\xi)}{2}h^{2}\quad \xi\in[0,h]</script><p>对 $L(h)$ 求导得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L'(h)&=-p+\frac{pe^{h}}{1-p+pe^{h}}\\
L''(h)&=\frac{pe^{h}(1-p+pe^{h})-p^{2}e^{2h}}{(1-p+pe^{h})^{2}}\\
&=\frac{pe^{h}}{1-p+pe^{h}}(1-\frac{pe^{h}}{1-p+pe^{h}})\\
&=t(1-t)\leq\frac{1}{4}(均值不等式ab\le(\frac{a+b}{2})^2)
\end{aligned}</script><p>可得 $L(0)=0,L’(0)=0$ ，所以</p>
<script type="math/tex; mode=display">
L(h)\leq\frac{1}{8}h^{2}=\frac{\lambda^{2}(b-a)^{2}}{8}</script><p>最终可得到</p>
<script type="math/tex; mode=display">
\mathbb{E}(e^{\lambda X})\le\exp \bigg\{\cfrac{\lambda^2(b-a)^2}{8}\bigg\}</script><p> $\square$ </p>
<hr>
<p><em>Proof~2~</em>:</p>
<p>设 $P$ 为 $X$ 的概率分布，定义 $L(\lambda):=\ln\mathbb{E}_P[e^{\lambda X}]$ 。</p>
<p>对 $L(\lambda)$ 在 $\lambda=0$ 出进行泰勒展开，得：</p>
<script type="math/tex; mode=display">
L(\lambda) = L(0)+L'(0)\lambda+\cfrac{L''(\lambda)\lambda^2}{2!}</script><p>其中 $\cfrac{L’’(\lambda)\lambda^2}{2!}$ 为拉格朗日余项。因此还需求得 $L’(0)$ 和 $\cfrac{L’’(\lambda)\lambda^2}{2!}$ 的值。求得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L'(\lambda)&=\cfrac{(\mathbb{E}_P[e^{\lambda X}])'}{\mathbb{E}_P[e^{\lambda X}]}
=\cfrac{\mathbb{E}_P[Xe^{\lambda X}]}{\mathbb{E}_P[e^{\lambda X}]}\\
L''(\lambda)&=\cfrac{\mathbb{E}_P[X^2e^{\lambda X}]\mathbb{E}_P[e^{\lambda X}]
-\mathbb{E}_P[Xe^{\lambda X}]^2}{\mathbb{E}_P[e^{\lambda X}]^2}\\
&=\cfrac{\mathbb{E}_P[X^2e^{\lambda X}]}{\mathbb{E}_P[e^{\lambda X}]}
-\cfrac{\mathbb{E}_P[Xe^{\lambda X}]^2}{\mathbb{E}_P[e^{\lambda X}]^2}
\end{aligned}</script><p>通过计算 $L(\lambda):=\ln\mathbb{E}_P[e^{\lambda X}]$ 泰勒展开式的每一项可得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L(0)&=ln(1)=0\\
L'(0)\lambda&=\cfrac{\mathbb{E}_P[Xe^{\lambda X}]}{\mathbb{E}_P[e^{\lambda X}]}\lambda
=E_P[X]\lambda=\mu\lambda
\end{aligned}</script><p>但是拉格朗日余项中的 $\lambda$ 不知其取值，所以只能求得其范围。</p>
<p>此时定义一个关于 $X$ 的分布 $Q_\lambda$ ：</p>
<script type="math/tex; mode=display">
\int{\rm d}Q_\lambda=\int\cfrac{e^{\lambda x}}{\mathbb{E}_p[e^{\lambda X}]}{\rm d}P(X)</script><p>所以，得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L'(\lambda)&=\cfrac{\mathbb{E}_P[Xe^{\lambda X}]}{\mathbb{E}_P[e^{\lambda X}]}
=\int x\cfrac{e^{\lambda x}}{\mathbb{E}_p[e^{\lambda X}]}{\rm d}P(X)
=\int x{\rm d}Q_\lambda(X)=\mathbb{E}_{Q_\lambda}[X]\\
L''(\lambda)&=\cfrac{\mathbb{E}_P[X^2e^{\lambda X}]}{\mathbb{E}_P[e^{\lambda X}]}
-\cfrac{\mathbb{E}_P[Xe^{\lambda X}]^2}{\mathbb{E}_P[e^{\lambda X}]^2}
=\mathbb{E}_{Q_\lambda}[X^2]-\mathbb{E}_{Q_\lambda}[X]^2=Var_{Q_\lambda}[X]
\end{aligned}</script><p>对于方差有以下性质：</p>
<p>随机变量 $X\in[a,b]$ 中，做一个变换，令 $Y=\frac{X-a}{b-a}$ ，可以明显得到 $Y\in[0,1]$ 。根据方差定义以及性质可以得到以下等式。</p>
<script type="math/tex; mode=display">
Var[Y]=Var\bigg[\cfrac{X-a}{b-a}\bigg]=\frac{Var[X]}{(b-a)^2}\\
\Rightarrow Var[X]=(b-a)^2Var[Y]=(b-a)^2(E[Y^2]-E^2[Y])</script><p>通过提下不等式</p>
<script type="math/tex; mode=display">
0\le Y\le 1\Rightarrow Y^2\le Y\Rightarrow\mathbb{E}[Y^2]\le\mathbb{E}[Y]</script><p>可推出以下不等式：</p>
<script type="math/tex; mode=display">
Var[X]\le(b-1)^2(\mathbb{E}[Y]-\mathbb{E}^2[Y])=(b-1)^2\mathbb{E}[Y](1-\mathbb{E}[Y])</script><p>通过均值不等式 $ab\ge(\frac{a+b}{2})^2$ 可得：</p>
<script type="math/tex; mode=display">
Var[X]\le\cfrac{(b-a)^2}{4}</script><p>所以可以得到 $L(\lambda)$ 的拉格朗日余项范围：</p>
<script type="math/tex; mode=display">
\cfrac{L''(\lambda)\lambda^2}{2!}=\cfrac{Var_{Q_\lambda}(X)\lambda^2}{2!}
\le\cfrac{(b-a)^2\lambda^2}{8}</script><p>综合以上可得到不等式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&L(\lambda)\le\mu\lambda+\cfrac{(b-a)^2\lambda^2}{8}\\
\Rightarrow&\ln \mathbb{E}_P[E^{\lambda X}]\le \mu\lambda+\cfrac{(b-a)^2\lambda^2}{8}\\
\Rightarrow&\mathbb{E}_P[E^{\lambda X}]\le\exp
\Big(\mu\lambda+\cfrac{(b-a)^2\lambda^2}{8}\Big)\\
\Rightarrow&\mathbb{E}_P[E^{\lambda X}]e^{-\mu\lambda}\le\exp
\Big(\cfrac{(b-a)^2\lambda^2}{8}\Big)(其中e^{-\mu\lambda}大于0)\\
\Rightarrow&\mathbb{E}_P[E^{\lambda (X-\mu)}]\le\exp
\Big(\cfrac{(\frac{b-a}{2})^2\lambda^2}{2}\Big)
\end{aligned}</script><p> $X$ 刚好是服从 $\frac{b-a}{2}$ 为参数的次高斯分布的定义。</p>
<p> $\square$ </p>
<hr>
<h3 id="Hoeffding’s-Inequality（霍夫丁不等式）"><a href="#Hoeffding’s-Inequality（霍夫丁不等式）" class="headerlink" title="Hoeffding’s Inequality（霍夫丁不等式）"></a>Hoeffding’s Inequality（霍夫丁不等式）</h3><p>关于次高斯的一些定理</p>
<blockquote>
<p>假设 $X$ 是 $\sigma$ 次高斯的 $r.v.$ ， $X_1,X_2$ 相互独立，分别为 $\sigma_1,\sigma_2$ 次高斯，则有：</p>
<ol>
<li><p>$Var[X]\le\sigma^2$ 。</p>
</li>
<li><p>$\forall c$ (c是常数)有 $cX$ 是 $|x|\sigma$ 次高斯的随机变量。</p>
</li>
<li><p>$X_1+X_2$ 是 $\sqrt{\sigma_1^2+\sigma_2^2}$ 次高斯的。</p>
</li>
</ol>
</blockquote>
<p><em>Proof</em>:</p>
<ol>
<li><p>设 $Y$ 为一个 $r.v.$ 定义为 $Y=X-\mathbb{E}[X]$ 。显然 $\mathbb{E}[Y]=0,Var[Y]=Var[X]$ 根据次高斯性的定义， $Y$ 也是次高斯 $r.v.$ 且次高斯参数也是 $\sigma$ 。</p>
<p>根据高斯的定义</p>
<script type="math/tex; mode=display">
M_Y(\lambda)\le e^{\frac{\sigma^2\lambda^2}{2}}</script><p>对于左侧将 $Y$ 的矩母函数在 $\lambda=0$ 附近泰勒展开，得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
M_Y(\lambda)&=M_Y(0)+\cfrac{M_Y'(0)}{1!}\lambda+\cfrac{M_Y''(0)}{2!}\lambda^2+
\cfrac{M_Y^{(3)}(\lambda_1)}{3!}\lambda^3\quad\lambda_1\in[0,\lambda]\\
&=1+0+\frac{1}{2}Var(Y)\lambda^2+\cfrac{M_Y^{(3)}(\lambda_1)}{6}\lambda^3
\end{aligned}</script><p>对于右侧设 $f(\lambda):=e^{\frac{\sigma^2\lambda^2}{2}}$ ，则 $f’(x)=e^{\frac{\sigma^2\lambda^2}{2}}\lambda\sigma^2,f’’(\lambda)=e^{\frac{\sigma^2\lambda^2}{2}}\lambda^2\sigma^4+e^{\frac{\sigma^2\lambda^2}{2}}\sigma^2$ ，在原点进行泰勒展开，得：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(\lambda)&=f(0)+\cfrac{f'(0)}{1!}\lambda+\cfrac{f''(0)}{2!}\lambda^2+
\cfrac{f^{(3)}(\lambda_2)}{3!}\lambda^3\quad\lambda_2\in[0,\lambda]\\
&=1+0+\frac{1}{2}\sigma^2\lambda^2+\cfrac{f^{(3)}(\lambda_2)}{6}\lambda^3
\end{aligned}</script><p>根据次高斯性的定义有 $M_Y(\lambda)\le f(\lambda)\quad\forall\lambda\in\mathbb{R}$ ，代入泰勒展开式得：</p>
</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}
&\frac{1}{2}Var(Y)\lambda^2+\cfrac{M_Y^{(3)}(\lambda_1)}{6}\lambda^3
\le\frac{1}{2}\sigma^2\lambda^2+\cfrac{f^{(3)}(\lambda_2)}{6}\lambda^3\\
限制\lambda\ne0,同除\lambda^2\Rightarrow&
\frac{1}{2}Var(Y)+\cfrac{M_Y^{(3)}(\lambda_1)}{6}\lambda\le
\frac{1}{2}\sigma^2+\cfrac{f^{(3)}(\lambda_2)}{6}\lambda\\
\Rightarrow&
\lim_{\lambda\rightarrow0}\frac{1}{2}Var(Y)+\cfrac{M_Y^{(3)}(\lambda_1)}{6}\lambda\le
\lim_{\lambda\rightarrow0}\frac{1}{2}\sigma^2+\cfrac{f^{(3)}(\lambda_2)}{6}\lambda\\
\Rightarrow&\frac{1}{2}Var(Y)\le\frac{1}{2}\sigma^2\\
\Rightarrow&Var(Y)\le\sigma^2\\
\Rightarrow&Var(X)\le\sigma^2
\end{aligned}</script><ol>
<li><p>因为 $X$ 是 $\sigma$ 次高斯分布的，根据次高斯性定义，有：</p>
<script type="math/tex; mode=display">
\mathbb{E}[e^{\lambda(X-\mu)}]\le e^{\frac{\lambda^2\sigma^2}{2}}
\quad\forall\lambda\in\mathbb{R}</script><p>$\because\mathbb{E}[X]=\mu\therefore\mathbb{E}[cX]=c\mu$ ，所以应当证明下式：</p>
<script type="math/tex; mode=display">
\mathbb{E}[e^{\lambda(cX-c\mu)}]\le \exp \{\frac{\lambda^2(|c|\sigma^2|)}{2}\}
\quad\forall\lambda\in\mathbb{R}</script><p>设 $\lambda’=c\lambda$ ，则有：</p>
<script type="math/tex; mode=display">
\mathbb{E}[e^{\lambda(cX-c\mu)}]=\mathbb{E}[e^{\lambda'(X-\mu)}]\le
e^{\frac{(\lambda')^2\sigma^2}{2}}=e^{\frac{c^2\lambda^2\sigma^2}{2}}
=e^{\frac{\lambda^2(|c|\sigma^2|)}{2}}</script><p>因此， $cX$ 是 $|c|\sigma$ 次高斯的。</p>
</li>
<li><p>$X_1+X_2$ 是 $\sqrt{\sigma^2+\sigma^2}$ 次高斯分布随机变量</p>
<p> $X_1$ 是 $\sigma_1$ 次高斯的， $\therefore\mathbb{E}[e^{\lambda(X_1-\mu_1)}]\le\exp \{\frac{\lambda^2\sigma_1^2}{2}\}$ </p>
<p> $X_2$ 是 $\sigma_2$ 次高斯的， $\therefore\mathbb{E}[e^{\lambda(X_2-\mu_2)}]\le\exp \{\frac{\lambda^2\sigma_2^2}{2}\}$ </p>
<p>则需要证明：$\mathbb{E}[\}]\le\exp \{\frac{\lambda^2(\sigma_1^2+\sigma_2^2)}{2}\}$ </p>
<script type="math/tex; mode=display">
\begin{aligned}
&\mathbb{E}[\exp \{\lambda[(X_1+X_2)-(\mu_1-\mu_2)]\}]\\
=&\mathbb{E}[\exp \{\lambda(X_1-\mu_1)+\lambda(X_2-\mu_2)\}]\\
=&\mathbb{E}[\exp \{\lambda(X_1-\mu_1)\}\cdot\exp \{\lambda(X_2-\mu_2)\}]\\
=&\mathbb{E}[\exp \{\lambda(X_1-\mu_1)\}]\cdot\mathbb{E}[\exp \{\lambda(X_2-\mu_2)\}]\\
\le&\exp \{\frac{\lambda^2\sigma_1^2}{2}\}\cdot\exp \{\frac{\lambda^2\sigma_2^2}{2}\}\\
=&\exp \{\frac{\lambda^2(\sigma_1^2+\sigma_2^2)}{2}\}\\
\end{aligned}</script><p>$\square$ </p>
</li>
</ol>
<blockquote>
<p><strong>霍夫丁界</strong>：</p>
<p>若随机变量 $X_1,X_2,\cdots,X_n$ 相互独立，且 $X_i$ 的均值为 $\mu_i$ ，次高斯参数为 $\sigma_i$ 。则对任意 $\epsilon\gt 0$ 有：</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{\epsilon^2}{2\sum_{i=1}^{n}\sigma_i^2}\bigg\}</script></blockquote>
<p><em>Proof</em>:</p>
<p>根据上面第三个定理 $X_1+X_2$ 是 $\sqrt{\sigma_1^2+\sigma_2^2}$ 次高斯可得 $\underset{i=1}{\overset{n}{\sum}}X_i$ 为 $\sqrt{\underset{i=1}{\overset{n}{\sum}}\sigma_i^2}$ 次高斯分布随机变量。</p>
<p>根据期望是线性的(可加性)有 $\mathbb{E}[\underset{i=1}{\overset{n}{\sum}}X_i]=\underset{i=1}{\overset{n}{\sum}}\mathbb{E}[X_i]=\underset{i=1}{\overset{n}{\sum}}\mu_i$ </p>
<p>根据霍夫丁引理中次高斯性的定理有</p>
<script type="math/tex; mode=display">
\mathbb{P}[(X-\mu)\ge\epsilon]\le e^{-\frac{\epsilon^2}{2\sigma^2}}</script><p>将参数代入可得：</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\sum_{i=1}^nX_i-\mathbb{E}[\underset{i=1}{\overset{n}{\sum}}X_i]\ge\epsilon\bigg]
=\mathbb{P}\bigg[\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{\epsilon^2}{2\sum_{i=1}^{n}\sigma_i^2}\bigg\}</script><p> $\square$ </p>
<blockquote>
<p><strong>霍夫丁不等式</strong>：</p>
<p>若随机变量 $X_1,X_2,\cdots,X_n$ 相互独立，且 $X_i\in[a_i,b_i]\quad\forall i\in[n]$ 则：</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{2\epsilon^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\bigg\}</script></blockquote>
<p><em>Proof~1~</em>:</p>
<p> $\because X_i\in[a_i,b_i]\quad\forall i\in[n]\quad\therefore$ 根据霍夫丁引理 $X_i$ 是 $\frac{b_i-a_i}{2}$ 次高斯的。</p>
<p>把次高斯参数代入霍夫丁界可得</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{\epsilon^2}{2\sum_{i=1}^{n}(\frac{b_i-a_i}{2})^2}\bigg\}
=\exp \bigg\{-\cfrac{2\epsilon^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\bigg\}</script><p> $\square$ </p>
<p><em>Proof~2~</em>:</p>
<p>令 $S_n=\underset{i=1}{\overset{n}{\sum}}X_i$ ，可得：</p>
<script type="math/tex; mode=display">
\mathbb{P}\{S_n-E[S_n]\ge\epsilon\}
=\mathbb{P}\{e^{\lambda(S_n-E[S_n])}\ge e^{\lambda\epsilon}\}\quad\lambda\gt 0</script><p>由马尔科夫不等式得：</p>
<script type="math/tex; mode=display">
\mathbb{P}\{e^{\lambda(S_n-E[S_n])}\ge e^{\lambda\epsilon}\}
\le\frac{\mathbb{E}[e^{\lambda(S_n-E[S_n])}]}{e^{\lambda\epsilon}}
=\frac{\mathbb{E}[e^{\lambda\sum_{i=1}^{n}(X_i-E[X_i])}]}{e^{\lambda\epsilon}}
=\frac{\prod_{i=1}^{n}\mathbb{E}[e^{\lambda(X_i-E[X_i])}]}{e^{\lambda\epsilon}}</script><p>有霍夫丁引理得：</p>
<script type="math/tex; mode=display">
e^{-\lambda\epsilon}\prod_{i=1}^{n}\mathbb{E}[e^{\lambda(X_i-E[X_i])}]
\le e^{-\lambda\epsilon}\prod_{i=1}^{n}e^{\frac{\lambda^2(b_i-a_i)^2}{8}}
=\exp \bigg\{-\lambda\epsilon+\sum_{i=1}^{n}\frac{\lambda^2(b_i-a_i)^2}{8}\bigg\}</script><p>令</p>
<script type="math/tex; mode=display">
g(\lambda)=-\lambda\epsilon+\sum_{i=1}^{n}\frac{\lambda^2(b_i-a_i)^2}{8}\quad\lambda\gt0</script><p>对 $g(\lambda)$ 求导：</p>
<script type="math/tex; mode=display">
g'(\lambda)=-\epsilon+\sum_{i=1}^{n}\frac{\lambda(b_i-a_i)^2}{4}</script><p>令 $g’(\lambda)=0$ 得：</p>
<script type="math/tex; mode=display">
\lambda^*=\frac{4\epsilon}{\sum_{i=1}^{n}(b_i-a_i)^2}\\
g(\lambda^*)=\frac{-2\epsilon^2}{\sum_{i=1}^{n}(b_i-a_i)^2}</script><p>综合上面的可得：</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{2\epsilon^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\bigg\}</script><p> $\square$ </p>
<blockquote>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\frac{1}{N}\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{2\epsilon^2N^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\bigg\}</script></blockquote>
<p><em>Proof</em>:</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\frac{1}{N}\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
=\mathbb{P}\bigg[\sum_{i=1}^n(X_i-\mu_i)\ge N\epsilon\bigg]</script><p>代入霍夫丁不等式可得</p>
<script type="math/tex; mode=display">
\mathbb{P}\bigg[\frac{1}{N}\sum_{i=1}^n(X_i-\mu_i)\ge\epsilon\bigg]
\le\exp \bigg\{-\cfrac{2\epsilon^2N^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\bigg\}\\
\Rightarrow\mathbb{P}[\bar{X}-\mathbb{E}[\bar{X}]\ge\epsilon]
\le\exp \bigg\{-\cfrac{2\epsilon^2N^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\bigg\}</script><p> $\square$ </p>
<hr>
<h2 id="泛化能力解释"><a href="#泛化能力解释" class="headerlink" title="泛化能力解释"></a>泛化能力解释</h2><h3 id="泛化能力（generalization-ability）"><a href="#泛化能力（generalization-ability）" class="headerlink" title="泛化能力（generalization ability）"></a>泛化能力（generalization ability）</h3><p>泛化能力表示学习方法学习到的模型对未知数据的预测能力，可以通过泛化误差来度量。理解为举一反三的能力。</p>
<h3 id="泛化误差（generalization-error）"><a href="#泛化误差（generalization-error）" class="headerlink" title="泛化误差（generalization error）"></a>泛化误差（generalization error）</h3><p>泛化误差表示用学习到的模型对未知数据进行预测的误差，定义如下：（假设学到的模型为 $\hat{f}$  ，L为损失函数）</p>
<script type="math/tex; mode=display">
\begin{aligned}
R_{exp}(f)\ &=\ \mathbb{E}_p[L(Y,\hat{f}(X))] \\
&= \int_{X\times Y}L(y,\hat{f}(x))P(x,y)dxdy
\end{aligned}</script><p>泛化误差也就是所学模型的误差期望值（即期望风险），反映了学习方法的泛化能力。</p>
<h3 id="泛化误差上界（generalization-error-bound）"><a href="#泛化误差上界（generalization-error-bound）" class="headerlink" title="泛化误差上界（generalization error bound）"></a>泛化误差上界（generalization error bound）</h3><p>学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为泛化误差上界。泛化误差即期望误差，由于其只存在理论意义，只能从理论上寻找泛化误差的概率上界。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">hjqecho</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/04/29/0_1Extra.%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E8%AF%81%E6%98%8E/">http://example.com/2022/04/29/0_1Extra.泛化能力证明/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">hjqecho</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://npm.elemecdn.com/hjqecho_img/custom/1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/05/01/Windows%E4%B8%8Bhexo%E5%92%8Cgithub%20pages%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/"><img class="prev-cover" src="https://npm.elemecdn.com/hjqecho_img/custom/3.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Windows下hexo和github pages搭建静态博客</div></div></a></div><div class="next-post pull-right"><a href="/2022/04/28/0_1Extra.%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89/"><img class="next-cover" src="https://npm.elemecdn.com/hjqecho_img/custom/2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">0_1Extra.数学定义</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="lv-container" data-id="city" data-uid="MTAyMC81NjM0NC8zMjgwNw"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://npm.elemecdn.com/hjqecho_img/favicon/favicon.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">hjqecho</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/hjqecho"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/hjqecho" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2454840488@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E8%AF%81%E6%98%8E"><span class="toc-text">泛化能力证明</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E5%AF%BC"><span class="toc-text">先导</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E6%80%A7%E8%B4%A8"><span class="toc-text">期望和方差的定义和性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E6%9C%9F%E6%9C%9B%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1"><span class="toc-text">样本期望和方差的无偏估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%BE%E6%A6%82%E7%8E%87"><span class="toc-text">尾概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A3%8E%E9%99%A9%E5%87%BD%E6%95%B0"><span class="toc-text">风险函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%8D%E5%A4%AB%E4%B8%81%E4%B8%8D%E7%AD%89%E5%BC%8F%E7%9A%84%E8%AF%81%E6%98%8E"><span class="toc-text">霍夫丁不等式的证明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81Markov%E2%80%99s-Inequality%EF%BC%88%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F%EF%BC%89"><span class="toc-text">一、Markov’s Inequality（马尔可夫不等式）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Chebyshev%E2%80%99s-Inequality%EF%BC%88%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F%EF%BC%89"><span class="toc-text">二、Chebyshev’s Inequality（切比雪夫不等式）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81Chernoff%E2%80%99s-bound%EF%BC%88%E5%88%87%E8%AF%BA%E5%A4%AB%E7%95%8C%EF%BC%89"><span class="toc-text">三、Chernoff’s bound（切诺夫界）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hoeffding%E2%80%99s-Lemma%EF%BC%88%E9%9C%8D%E5%A4%AB%E4%B8%81%E5%BC%95%E7%90%86%EF%BC%89"><span class="toc-text">Hoeffding’s Lemma（霍夫丁引理）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hoeffding%E2%80%99s-Inequality%EF%BC%88%E9%9C%8D%E5%A4%AB%E4%B8%81%E4%B8%8D%E7%AD%89%E5%BC%8F%EF%BC%89"><span class="toc-text">Hoeffding’s Inequality（霍夫丁不等式）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E8%A7%A3%E9%87%8A"><span class="toc-text">泛化能力解释</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%EF%BC%88generalization-ability%EF%BC%89"><span class="toc-text">泛化能力（generalization ability）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%9B%E5%8C%96%E8%AF%AF%E5%B7%AE%EF%BC%88generalization-error%EF%BC%89"><span class="toc-text">泛化误差（generalization error）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%9B%E5%8C%96%E8%AF%AF%E5%B7%AE%E4%B8%8A%E7%95%8C%EF%BC%88generalization-error-bound%EF%BC%89"><span class="toc-text">泛化误差上界（generalization error bound）</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recommend-post"><div class="item-headline"><i class="fas fa-dharmachakra"></i><span>相关推荐</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/04/28/0_1Extra.%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89/" title="0_1Extra.数学定义"><img src="https://npm.elemecdn.com/hjqecho_img/custom/2.jpg" alt="0_1Extra.数学定义"></a><div class="content"><a class="title" href="/2022/04/28/0_1Extra.%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89/" title="0_1Extra.数学定义">0_1Extra.数学定义</a><time datetime="2022-04-28" title="发表于 2022-04-28">2022-04-28</time></div></div></div></div><!--!=partial('includes/widget/card_recent_post', {}, {cache: true})--></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 <i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;" class="fa fa-heartbeat"></i> hjqecho</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Livere' === 'Livere' || !true) {
  if (true) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script></div><script defer src="/live2d-widget/autoload.js"></script><script defer src="/js/custom/custom.js"></script><div class="aplayer no-destroy" data-id="7428431419" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-autoplay="false" data-theme="#393d58" data-order="random" data-preload="auto" data-volume="0.7" > </div><script async src="//at.alicdn.com/t/font_3396227_4br22qp6h48.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.6" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="true"></script><script src="https://code.tidio.co/lfztfoice4ykd7q1j5i1v44s2amxkwof.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/04/29/0_1Extra.泛化能力证明/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/hjqecho_img/custom/1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-04-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/04/29/0_1Extra.泛化能力证明/&quot;);" href="javascript:void(0);" alt="">0_1Extra.泛化能力证明</a><div class="blog-slider__text">泛化能力证明</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/04/29/0_1Extra.泛化能力证明/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/05/01/Windows下hexo和github pages搭建静态博客/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/hjqecho_img/custom/3.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-05-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/05/01/Windows下hexo和github pages搭建静态博客/&quot;);" href="javascript:void(0);" alt="">Windows下hexo和github pages搭建静态博客</a><div class="blog-slider__text">Windows下hexo和github pages搭建静态博客</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/05/01/Windows下hexo和github pages搭建静态博客/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;2022/04/28/0_1Extra.数学定义/&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/hjqecho_img/custom/2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-04-28</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;2022/04/28/0_1Extra.数学定义/&quot;);" href="javascript:void(0);" alt="">0_1Extra.数学定义</a><div class="blog-slider__text">一些数学定义</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;2022/04/28/0_1Extra.数学定义/&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>